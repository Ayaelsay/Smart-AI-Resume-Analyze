import streamlit as st
import requests
import pdfplumber
import re

# Ø¹Ù†ÙˆØ§Ù† API Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©
API_URL = "https://3bd2-197-56-115-126.ngrok-free.app/analyze_cv"


# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø´Ø±ÙƒØ§Øª ÙˆÙ…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù‡Ø§
COMPANIES = {
    "Google": {"skills": ["python", "ml", "ai", "tensorflow"], "min_experience": 3},
    "Microsoft": {"skills": ["c#", "azure", "sql", "dotnet"], "min_experience": 2},
    "Amazon": {"skills": ["aws", "java", "cloud", "devops"], "min_experience": 3},
    "Facebook": {"skills": ["react", "javascript", "frontend", "ui/ux"], "min_experience": 4},
    "Tesla": {"skills": ["automation", "robotics", "ai", "python"], "min_experience": 5}
}

def extract_text_from_pdf(uploaded_file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù PDF"""
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text.strip()

def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    return re.sub(r'\s+', ' ', text).strip()

def extract_phone_numbers(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ"""
    phone_pattern = re.compile(r'\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}')
    return list(set(phone_pattern.findall(text)))

def recommend_companies(skills, experience_years):
    """ØªØ±Ø´ÙŠØ­ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª ÙˆØ³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©"""
    matched_companies = {}
    for company, data in COMPANIES.items():
        missing_skills = [skill for skill in data["skills"] if skill not in skills]
        experience_needed = data["min_experience"] - experience_years
        if len(missing_skills) < len(data["skills"]):  # Ù„Ø¯ÙŠÙ‡ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            matched_companies[company] = {"missing_skills": missing_skills, "experience_needed": max(0, experience_needed)}
    return matched_companies

def upload_and_analyze_pdf():
    """Ø±ÙØ¹ Ù…Ù„Ù PDF ÙˆØªØ­Ù„ÙŠÙ„Ù‡"""
    st.subheader("ğŸ“‚ Ù‚Ù… Ø¨Ø±ÙØ¹ Ø³ÙŠØ±ØªÙƒ Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨ØµÙŠØºØ© PDF")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù PDF", type=["pdf"])
    
    if uploaded_file is not None:
        st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
        extracted_text = clean_text(extract_text_from_pdf(uploaded_file))
        phone_numbers = extract_phone_numbers(extracted_text)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ API
        files = {"file": uploaded_file.getvalue()}
        response = requests.post(API_URL, files=files)
        
        if response.status_code == 200:
            data = response.json()
            st.subheader("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:")
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„
            st.write("ğŸ“§ **Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ:**", ", ".join(data['contact_info']['emails']))
            st.write("ğŸ“ **Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ:**", ", ".join(phone_numbers) if phone_numbers else "ØºÙŠØ± Ù…ØªÙˆÙØ±")
            
            # Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„Ø®Ø¨Ø±Ø§Øª
            experience_years = data.get("experience_years", "ØºÙŠØ± Ù…ØªÙˆÙØ±")
            try:
                experience_years = int(experience_years)
            except ValueError:
                experience_years = 0  # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©
            
            st.write("ğŸ“ **Ø§Ù„ØªØ¹Ù„ÙŠÙ…:**", "\n".join(data["education"]))
            st.write("ğŸ’¼ **Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø©:**", experience_years if experience_years else "ØºÙŠØ± Ù…ØªÙˆÙØ±")
            
            if experience_years < 2:
                st.warning("âš ï¸ Ù„Ø¯ÙŠÙƒ Ø®Ø¨Ø±Ø© Ù‚Ù„ÙŠÙ„Ø©ØŒ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§ÙƒØªØ³Ø§Ø¨ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø®Ø¨Ø±Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ… Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ø´Ø±ÙƒØ§Øª.")
            
            # Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª ÙˆØªØ±Ø´ÙŠØ­ Ø§Ù„Ø´Ø±ÙƒØ§Øª
            skills = data.get("skills", [])
            st.write("ğŸ›  **Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**", ", ".join(skills))
            
            recommended_companies = recommend_companies(skills, experience_years)
            if recommended_companies:
                st.subheader("ğŸ¢ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ùƒ:")
                for company, details in recommended_companies.items():
                    missing_skills = details["missing_skills"]
                    experience_needed = details["experience_needed"]
                    message = f"âœ… {company}"
                    if missing_skills:
                        message += f" (Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ©: {', '.join(missing_skills)})"
                    if experience_needed > 0:
                        message += f" | âš ï¸ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ {experience_needed} Ø³Ù†ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ø§Ù„Ø®Ø¨Ø±Ø©."
                    else:
                        message += " | âœ… Ù„Ø¯ÙŠÙƒ Ø§Ù„Ø®Ø¨Ø±Ø© Ø§Ù„ÙƒØ§ÙÙŠØ©."
                    st.write(message)
            else:
                st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´Ø±ÙƒØ§Øª ØªÙ†Ø§Ø³Ø¨ Ù…Ù‡Ø§Ø±Ø§ØªÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
            
            # ØªØ­Ù„ÙŠÙ„ BERT
            st.write("ğŸ¤– **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BERT:**")
            st.json(data["bert_analysis"])
            
            # Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
            st.write("ğŸ“„ **Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:**")
            st.text(extracted_text[:500])
        else:
            st.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.title("ğŸ“„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
upload_and_analyze_pdf()
